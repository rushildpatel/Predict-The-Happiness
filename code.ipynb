{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Embedding, LSTM, Dense,Dropout,GRU,Masking\n",
    "from keras.models import Model\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "tot_data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10326</td>\n",
       "      <td>The room was kind of clean but had a VERY stro...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10327</td>\n",
       "      <td>I stayed at the Crown Plaza April -- - April -...</td>\n",
       "      <td>Internet Explorer</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10328</td>\n",
       "      <td>I booked this hotel through Hotwire at the low...</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10329</td>\n",
       "      <td>Stayed here with husband and sons on the way t...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10330</td>\n",
       "      <td>My girlfriends and I stayed here to celebrate ...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                                        Description  \\\n",
       "0  id10326  The room was kind of clean but had a VERY stro...   \n",
       "1  id10327  I stayed at the Crown Plaza April -- - April -...   \n",
       "2  id10328  I booked this hotel through Hotwire at the low...   \n",
       "3  id10329  Stayed here with husband and sons on the way t...   \n",
       "4  id10330  My girlfriends and I stayed here to celebrate ...   \n",
       "\n",
       "        Browser_Used Device_Used Is_Response  \n",
       "0               Edge      Mobile   not happy  \n",
       "1  Internet Explorer      Mobile   not happy  \n",
       "2            Mozilla      Tablet   not happy  \n",
       "3   InternetExplorer     Desktop       happy  \n",
       "4               Edge      Tablet   not happy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id80132</td>\n",
       "      <td>Looking for a motel in close proximity to TV t...</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id80133</td>\n",
       "      <td>Walking distance to Madison Square Garden and ...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id80134</td>\n",
       "      <td>Visited Seattle on business. Spent - nights in...</td>\n",
       "      <td>IE</td>\n",
       "      <td>Tablet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id80135</td>\n",
       "      <td>This hotel location is excellent and the rooms...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id80136</td>\n",
       "      <td>This hotel is awesome I love the service Antho...</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                                        Description  \\\n",
       "0  id80132  Looking for a motel in close proximity to TV t...   \n",
       "1  id80133  Walking distance to Madison Square Garden and ...   \n",
       "2  id80134  Visited Seattle on business. Spent - nights in...   \n",
       "3  id80135  This hotel location is excellent and the rooms...   \n",
       "4  id80136  This hotel is awesome I love the service Antho...   \n",
       "\n",
       "       Browser_Used Device_Used  \n",
       "0           Firefox      Mobile  \n",
       "1  InternetExplorer     Desktop  \n",
       "2                IE      Tablet  \n",
       "3              Edge      Mobile  \n",
       "4           Mozilla      Mobile  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_data=tot_data[['Browser_Used','Device_Used']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edge</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Internet Explorer</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Tablet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edge</td>\n",
       "      <td>Tablet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Browser_Used Device_Used\n",
       "0               Edge      Mobile\n",
       "1  Internet Explorer      Mobile\n",
       "2            Mozilla      Tablet\n",
       "3   InternetExplorer     Desktop\n",
       "4               Edge      Tablet"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Firefox              13043\n",
       "Edge                 12437\n",
       "InternetExplorer      8191\n",
       "Google Chrome         8050\n",
       "Mozilla Firefox       7526\n",
       "Mozilla               5425\n",
       "Chrome                4356\n",
       "IE                    4270\n",
       "Internet Explorer     3700\n",
       "Safari                 670\n",
       "Opera                  668\n",
       "Name: Browser_Used, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_data.Browser_Used.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_data['Browser_Used']=other_data.Browser_Used.replace(['Mozilla Firefox','Mozilla'],'Firefox')\n",
    "other_data['Browser_Used']=other_data.Browser_Used.replace(['IE','Internet Explorer'],'InternetExplorer')\n",
    "other_data['Browser_Used']=other_data.Browser_Used.replace('Chrome','Google Chrome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Firefox             25994\n",
       "InternetExplorer    16161\n",
       "Edge                12437\n",
       "Google Chrome       12406\n",
       "Safari                670\n",
       "Opera                 668\n",
       "Name: Browser_Used, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_data.Browser_Used.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Desktop    26375\n",
       "Mobile     26214\n",
       "Tablet     15747\n",
       "Name: Device_Used, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_data.Device_Used.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_data=pd.get_dummies(other_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The room was kind of clean but had a VERY stro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I stayed at the Crown Plaza April -- - April -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I booked this hotel through Hotwire at the low...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stayed here with husband and sons on the way t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My girlfriends and I stayed here to celebrate ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description\n",
       "0  The room was kind of clean but had a VERY stro...\n",
       "1  I stayed at the Crown Plaza April -- - April -...\n",
       "2  I booked this hotel through Hotwire at the low...\n",
       "3  Stayed here with husband and sons on the way t...\n",
       "4  My girlfriends and I stayed here to celebrate ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_data.drop('User_ID', inplace=True, axis=1)\n",
    "tot_data.drop('Browser_Used', inplace=True, axis=1)\n",
    "tot_data.drop('Device_Used', inplace=True, axis=1)\n",
    "tot_data.drop('Is_Response', inplace=True, axis=1)\n",
    "tot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target=train['Is_Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting text to lower case\n",
    "tot_data = np.array(tot_data['Description'])\n",
    "for i in range(0,len(tot_data)):\n",
    "    tot_data[i] = tot_data[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tokenizing text\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for i in range(0,len(tot_data)):\n",
    "    tot_data[i] = tokenizer.tokenize(tot_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stop word removal\n",
    "from nltk.corpus import stopwords\n",
    "stop=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'room',\n",
       " 'was',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'clean',\n",
       " 'but',\n",
       " 'had',\n",
       " 'a',\n",
       " 'very',\n",
       " 'strong',\n",
       " 'smell',\n",
       " 'of',\n",
       " 'dogs',\n",
       " 'generally',\n",
       " 'below',\n",
       " 'average',\n",
       " 'but',\n",
       " 'ok',\n",
       " 'for',\n",
       " 'a',\n",
       " 'overnight',\n",
       " 'stay',\n",
       " 'if',\n",
       " 'you',\n",
       " 're',\n",
       " 'not',\n",
       " 'too',\n",
       " 'fussy',\n",
       " 'would',\n",
       " 'consider',\n",
       " 'staying',\n",
       " 'again',\n",
       " 'if',\n",
       " 'the',\n",
       " 'price',\n",
       " 'was',\n",
       " 'right',\n",
       " 'breakfast',\n",
       " 'was',\n",
       " 'free',\n",
       " 'and',\n",
       " 'just',\n",
       " 'about',\n",
       " 'better',\n",
       " 'than',\n",
       " 'nothing']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(tot_data)):\n",
    "    tot_data[i]=\" \".join(token for token in tot_data[i] if token not in stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for i in range(0,len(tot_data)):\n",
    "    tot_data[i] = tokenizer.tokenize(tot_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['room',\n",
       " 'kind',\n",
       " 'clean',\n",
       " 'strong',\n",
       " 'smell',\n",
       " 'dogs',\n",
       " 'generally',\n",
       " 'average',\n",
       " 'ok',\n",
       " 'overnight',\n",
       " 'stay',\n",
       " 'fussy',\n",
       " 'would',\n",
       " 'consider',\n",
       " 'staying',\n",
       " 'price',\n",
       " 'right',\n",
       " 'breakfast',\n",
       " 'free',\n",
       " 'better',\n",
       " 'nothing']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Word2Vec model\n",
    "model_wv = Word2Vec(tot_data,size =100,window = 5,min_count =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tot_seq=np.zeros([68336,400,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.zeros([100])\n",
    "for i in range(0,68336):\n",
    "    a = model_wv.wv[tot_data[i]]\n",
    "    if(len(a) >400):\n",
    "        a = a[0:400]\n",
    "    for j in range(0,(400-len(a))):\n",
    "        a = np.vstack([a,b])\n",
    "    tot_seq[i] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_wv\n",
    "del a \n",
    "del b\n",
    "del tot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68336, 400, 100)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(tot_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = pd.get_dummies(target)\n",
    "target=target['happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dat = tot_seq[0:38932]\n",
    "test_dat = tot_seq[38932:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38932, 400, 100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LSTM model\n",
    "main_input = Input(shape = (400,100))\n",
    "mask=Masking(mask_value=0.0)(main_input)\n",
    "\n",
    "lstm_out = LSTM(256)(mask)\n",
    "out=Dense(64)(lstm_out)\n",
    "output = Dense(1,activation = 'sigmoid')(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 400, 100)          0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, 400, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               365568    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 382,081\n",
      "Trainable params: 382,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=main_input,outputs=output)\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31145 samples, validate on 7787 samples\n",
      "Epoch 1/4\n",
      "31145/31145 [==============================] - 1473s 47ms/step - loss: 0.3543 - acc: 0.8516 - val_loss: 0.3138 - val_acc: 0.8668\n",
      "Epoch 2/4\n",
      "31145/31145 [==============================] - 1393s 45ms/step - loss: 0.2875 - acc: 0.8805 - val_loss: 0.2919 - val_acc: 0.8793\n",
      "Epoch 3/4\n",
      "31145/31145 [==============================] - 1416s 45ms/step - loss: 0.2638 - acc: 0.8925 - val_loss: 0.2864 - val_acc: 0.8792\n",
      "Epoch 4/4\n",
      "31145/31145 [==============================] - 1419s 46ms/step - loss: 0.2378 - acc: 0.9033 - val_loss: 0.2966 - val_acc: 0.8789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129b86320>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dat,target,batch_size=64,epochs= 4,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model to extract output from last but one layer\n",
    "main_input2 = Input(shape = (400,100))\n",
    "mask2=Masking(mask_value=0.0)(main_input2)\n",
    "\n",
    "lstm_out2 = LSTM(256,weights = model.layers[2].get_weights())(mask2)\n",
    "out2=Dense(64,weights = model.layers[3].get_weights())(lstm_out2)\n",
    "\n",
    "model2 = Model(inputs=main_input2,outputs=out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_transformed = model2.predict(train_dat)\n",
    "test_transformed = model2.predict(test_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Concatenating output from last but layer and other_data that is provided apart from review.\n",
    "other_data=np.array(other_data)\n",
    "other_data_train=other_data[0:38932]\n",
    "other_data_test=other_data[38932:]\n",
    "\n",
    "train_transformed = np.concatenate([train_transformed,other_data_train],axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_new,valid_new,y_train_new,y_valid_new=train_test_split(train_transformed,target,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31145, 73)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 73)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 73)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               7400      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 9,441\n",
      "Trainable params: 9,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Feed Forward Neural on total data\n",
    "main_input3 = Input(shape = (73,))\n",
    "drop0 = Dropout(0.2)(main_input3)\n",
    "deninp1=Dense(100)(drop0)\n",
    "drop1 = Dropout(0.5)(deninp1)\n",
    "deninp2=Dense(20)(drop1)\n",
    "output3 = Dense(1,activation = 'sigmoid')(deninp2)\n",
    "\n",
    "\n",
    "model3 = Model(inputs=main_input3,outputs=output3)\n",
    "model3.compile('ADAM', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31145 samples, validate on 7787 samples\n",
      "Epoch 1/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2053 - acc: 0.9191 - val_loss: 0.1959 - val_acc: 0.9250\n",
      "Epoch 2/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2039 - acc: 0.9217 - val_loss: 0.1962 - val_acc: 0.9245\n",
      "Epoch 3/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2045 - acc: 0.9213 - val_loss: 0.1968 - val_acc: 0.9251\n",
      "Epoch 4/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2048 - acc: 0.9215 - val_loss: 0.1955 - val_acc: 0.9253\n",
      "Epoch 5/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2033 - acc: 0.9222 - val_loss: 0.1943 - val_acc: 0.9269\n",
      "Epoch 6/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2036 - acc: 0.9212 - val_loss: 0.1952 - val_acc: 0.9267\n",
      "Epoch 7/100\n",
      "31145/31145 [==============================] - 1s 41us/step - loss: 0.2037 - acc: 0.9211 - val_loss: 0.1953 - val_acc: 0.9256\n",
      "Epoch 8/100\n",
      "31145/31145 [==============================] - 1s 40us/step - loss: 0.2044 - acc: 0.9207 - val_loss: 0.1946 - val_acc: 0.9263\n",
      "Epoch 9/100\n",
      "31145/31145 [==============================] - 1s 42us/step - loss: 0.2034 - acc: 0.9219 - val_loss: 0.1952 - val_acc: 0.9267\n",
      "Epoch 10/100\n",
      "31145/31145 [==============================] - 1s 40us/step - loss: 0.2041 - acc: 0.9223 - val_loss: 0.1946 - val_acc: 0.9269\n",
      "Epoch 11/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2041 - acc: 0.9218 - val_loss: 0.1945 - val_acc: 0.9262\n",
      "Epoch 12/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2036 - acc: 0.9214 - val_loss: 0.1954 - val_acc: 0.9259\n",
      "Epoch 13/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2036 - acc: 0.9221 - val_loss: 0.1948 - val_acc: 0.9258\n",
      "Epoch 14/100\n",
      "31145/31145 [==============================] - 1s 47us/step - loss: 0.2031 - acc: 0.9227 - val_loss: 0.1950 - val_acc: 0.9259\n",
      "Epoch 15/100\n",
      "31145/31145 [==============================] - 1s 41us/step - loss: 0.2034 - acc: 0.9222 - val_loss: 0.1966 - val_acc: 0.9260\n",
      "Epoch 16/100\n",
      "31145/31145 [==============================] - 1s 40us/step - loss: 0.2035 - acc: 0.9226 - val_loss: 0.1943 - val_acc: 0.9268\n",
      "Epoch 17/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2046 - acc: 0.9220 - val_loss: 0.1948 - val_acc: 0.9254\n",
      "Epoch 18/100\n",
      "31145/31145 [==============================] - 1s 40us/step - loss: 0.2038 - acc: 0.9221 - val_loss: 0.1945 - val_acc: 0.9265\n",
      "Epoch 19/100\n",
      "31145/31145 [==============================] - 1s 44us/step - loss: 0.2034 - acc: 0.9217 - val_loss: 0.1944 - val_acc: 0.9269\n",
      "Epoch 20/100\n",
      "31145/31145 [==============================] - 1s 42us/step - loss: 0.2035 - acc: 0.9206 - val_loss: 0.1954 - val_acc: 0.9251\n",
      "Epoch 21/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2043 - acc: 0.9210 - val_loss: 0.1960 - val_acc: 0.9267\n",
      "Epoch 22/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2034 - acc: 0.9222 - val_loss: 0.1946 - val_acc: 0.9259\n",
      "Epoch 23/100\n",
      "31145/31145 [==============================] - 1s 43us/step - loss: 0.2033 - acc: 0.9236 - val_loss: 0.1949 - val_acc: 0.9260\n",
      "Epoch 24/100\n",
      "31145/31145 [==============================] - 1s 40us/step - loss: 0.2038 - acc: 0.9217 - val_loss: 0.1961 - val_acc: 0.9267\n",
      "Epoch 25/100\n",
      "31145/31145 [==============================] - 1s 40us/step - loss: 0.2035 - acc: 0.9222 - val_loss: 0.1953 - val_acc: 0.9262\n",
      "Epoch 26/100\n",
      "31145/31145 [==============================] - 1s 41us/step - loss: 0.2039 - acc: 0.9210 - val_loss: 0.1946 - val_acc: 0.9253\n",
      "Epoch 27/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2040 - acc: 0.9224 - val_loss: 0.1946 - val_acc: 0.9256\n",
      "Epoch 28/100\n",
      "31145/31145 [==============================] - 1s 41us/step - loss: 0.2027 - acc: 0.9216 - val_loss: 0.1960 - val_acc: 0.9264\n",
      "Epoch 29/100\n",
      "31145/31145 [==============================] - 2s 49us/step - loss: 0.2025 - acc: 0.9223 - val_loss: 0.1956 - val_acc: 0.9251\n",
      "Epoch 30/100\n",
      "31145/31145 [==============================] - 1s 40us/step - loss: 0.2043 - acc: 0.9215 - val_loss: 0.1961 - val_acc: 0.9255\n",
      "Epoch 31/100\n",
      "31145/31145 [==============================] - 1s 42us/step - loss: 0.2030 - acc: 0.9220 - val_loss: 0.1952 - val_acc: 0.9262\n",
      "Epoch 32/100\n",
      "31145/31145 [==============================] - 1s 46us/step - loss: 0.2036 - acc: 0.9222 - val_loss: 0.1964 - val_acc: 0.9250\n",
      "Epoch 33/100\n",
      "31145/31145 [==============================] - 1s 42us/step - loss: 0.2042 - acc: 0.9217 - val_loss: 0.1943 - val_acc: 0.9258\n",
      "Epoch 34/100\n",
      "31145/31145 [==============================] - 1s 42us/step - loss: 0.2025 - acc: 0.9208 - val_loss: 0.1948 - val_acc: 0.9255\n",
      "Epoch 35/100\n",
      "31145/31145 [==============================] - 1s 43us/step - loss: 0.2029 - acc: 0.9229 - val_loss: 0.1949 - val_acc: 0.9260\n",
      "Epoch 36/100\n",
      "31145/31145 [==============================] - 1s 42us/step - loss: 0.2036 - acc: 0.9224 - val_loss: 0.1951 - val_acc: 0.9258\n",
      "Epoch 37/100\n",
      "31145/31145 [==============================] - 1s 40us/step - loss: 0.2040 - acc: 0.9226 - val_loss: 0.1948 - val_acc: 0.9258\n",
      "Epoch 38/100\n",
      "31145/31145 [==============================] - 1s 43us/step - loss: 0.2030 - acc: 0.9225 - val_loss: 0.1949 - val_acc: 0.9256\n",
      "Epoch 39/100\n",
      "31145/31145 [==============================] - 1s 46us/step - loss: 0.2041 - acc: 0.9215 - val_loss: 0.1952 - val_acc: 0.9256\n",
      "Epoch 40/100\n",
      "31145/31145 [==============================] - 1s 43us/step - loss: 0.2044 - acc: 0.9218 - val_loss: 0.1951 - val_acc: 0.9263\n",
      "Epoch 41/100\n",
      "31145/31145 [==============================] - 1s 44us/step - loss: 0.2031 - acc: 0.9212 - val_loss: 0.1952 - val_acc: 0.9255\n",
      "Epoch 42/100\n",
      "31145/31145 [==============================] - 1s 42us/step - loss: 0.2032 - acc: 0.9221 - val_loss: 0.1949 - val_acc: 0.9259\n",
      "Epoch 43/100\n",
      "31145/31145 [==============================] - 1s 42us/step - loss: 0.2046 - acc: 0.9219 - val_loss: 0.1951 - val_acc: 0.9260\n",
      "Epoch 44/100\n",
      "31145/31145 [==============================] - 1s 42us/step - loss: 0.2031 - acc: 0.9219 - val_loss: 0.1950 - val_acc: 0.9255\n",
      "Epoch 45/100\n",
      "31145/31145 [==============================] - 1s 41us/step - loss: 0.2029 - acc: 0.9218 - val_loss: 0.1945 - val_acc: 0.9263\n",
      "Epoch 46/100\n",
      "31145/31145 [==============================] - 1s 45us/step - loss: 0.2036 - acc: 0.9213 - val_loss: 0.1945 - val_acc: 0.9263\n",
      "Epoch 47/100\n",
      "31145/31145 [==============================] - 1s 41us/step - loss: 0.2044 - acc: 0.9220 - val_loss: 0.1945 - val_acc: 0.9264\n",
      "Epoch 48/100\n",
      "31145/31145 [==============================] - 1s 45us/step - loss: 0.2045 - acc: 0.9211 - val_loss: 0.1954 - val_acc: 0.9253\n",
      "Epoch 49/100\n",
      "31145/31145 [==============================] - 1s 41us/step - loss: 0.2017 - acc: 0.9228 - val_loss: 0.1954 - val_acc: 0.9277\n",
      "Epoch 50/100\n",
      "31145/31145 [==============================] - 1s 40us/step - loss: 0.2042 - acc: 0.9209 - val_loss: 0.1957 - val_acc: 0.9258\n",
      "Epoch 51/100\n",
      "31145/31145 [==============================] - 1s 40us/step - loss: 0.2035 - acc: 0.9222 - val_loss: 0.1951 - val_acc: 0.9259\n",
      "Epoch 52/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2033 - acc: 0.9223 - val_loss: 0.1953 - val_acc: 0.9250\n",
      "Epoch 53/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2031 - acc: 0.9225 - val_loss: 0.1966 - val_acc: 0.9250\n",
      "Epoch 54/100\n",
      "31145/31145 [==============================] - 1s 40us/step - loss: 0.2029 - acc: 0.9213 - val_loss: 0.1951 - val_acc: 0.9260\n",
      "Epoch 55/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2047 - acc: 0.9216 - val_loss: 0.1951 - val_acc: 0.9254\n",
      "Epoch 56/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2030 - acc: 0.9221 - val_loss: 0.1950 - val_acc: 0.9258\n",
      "Epoch 57/100\n",
      "31145/31145 [==============================] - 1s 40us/step - loss: 0.2037 - acc: 0.9216 - val_loss: 0.1954 - val_acc: 0.9262\n",
      "Epoch 58/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2036 - acc: 0.9222 - val_loss: 0.1971 - val_acc: 0.9247\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2026 - acc: 0.9228 - val_loss: 0.1964 - val_acc: 0.9259\n",
      "Epoch 60/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2037 - acc: 0.9203 - val_loss: 0.1948 - val_acc: 0.9251\n",
      "Epoch 61/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2036 - acc: 0.9214 - val_loss: 0.1945 - val_acc: 0.9258\n",
      "Epoch 62/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2043 - acc: 0.9206 - val_loss: 0.1959 - val_acc: 0.9251\n",
      "Epoch 63/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2017 - acc: 0.9219 - val_loss: 0.1950 - val_acc: 0.9259\n",
      "Epoch 64/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2026 - acc: 0.9220 - val_loss: 0.1946 - val_acc: 0.9263\n",
      "Epoch 65/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2033 - acc: 0.9218 - val_loss: 0.1967 - val_acc: 0.9260\n",
      "Epoch 66/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2042 - acc: 0.9223 - val_loss: 0.1951 - val_acc: 0.9258\n",
      "Epoch 67/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2039 - acc: 0.9218 - val_loss: 0.1952 - val_acc: 0.9267\n",
      "Epoch 68/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2025 - acc: 0.9210 - val_loss: 0.1947 - val_acc: 0.9260\n",
      "Epoch 69/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2039 - acc: 0.9207 - val_loss: 0.1950 - val_acc: 0.9249\n",
      "Epoch 70/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2034 - acc: 0.9222 - val_loss: 0.1945 - val_acc: 0.9256\n",
      "Epoch 71/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2036 - acc: 0.9207 - val_loss: 0.1952 - val_acc: 0.9258\n",
      "Epoch 72/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2033 - acc: 0.9216 - val_loss: 0.1950 - val_acc: 0.9258\n",
      "Epoch 73/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2028 - acc: 0.9214 - val_loss: 0.1963 - val_acc: 0.9255\n",
      "Epoch 74/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2044 - acc: 0.9214 - val_loss: 0.1951 - val_acc: 0.9256\n",
      "Epoch 75/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2022 - acc: 0.9219 - val_loss: 0.1941 - val_acc: 0.9267\n",
      "Epoch 76/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2019 - acc: 0.9212 - val_loss: 0.1949 - val_acc: 0.9273\n",
      "Epoch 77/100\n",
      "31145/31145 [==============================] - 1s 37us/step - loss: 0.2029 - acc: 0.9214 - val_loss: 0.1948 - val_acc: 0.9264\n",
      "Epoch 78/100\n",
      "31145/31145 [==============================] - 1s 37us/step - loss: 0.2038 - acc: 0.9209 - val_loss: 0.1950 - val_acc: 0.9253\n",
      "Epoch 79/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2028 - acc: 0.9219 - val_loss: 0.1944 - val_acc: 0.9260\n",
      "Epoch 80/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2047 - acc: 0.9210 - val_loss: 0.1964 - val_acc: 0.9254\n",
      "Epoch 81/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2028 - acc: 0.9226 - val_loss: 0.1948 - val_acc: 0.9256\n",
      "Epoch 82/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2029 - acc: 0.9216 - val_loss: 0.1943 - val_acc: 0.9259\n",
      "Epoch 83/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2035 - acc: 0.9215 - val_loss: 0.1944 - val_acc: 0.9258\n",
      "Epoch 84/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2027 - acc: 0.9224 - val_loss: 0.1950 - val_acc: 0.9262\n",
      "Epoch 85/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2026 - acc: 0.9221 - val_loss: 0.1948 - val_acc: 0.9263\n",
      "Epoch 86/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2021 - acc: 0.9218 - val_loss: 0.1943 - val_acc: 0.9256\n",
      "Epoch 87/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2037 - acc: 0.9215 - val_loss: 0.1948 - val_acc: 0.9264\n",
      "Epoch 88/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2027 - acc: 0.9218 - val_loss: 0.1945 - val_acc: 0.9263\n",
      "Epoch 89/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2035 - acc: 0.9216 - val_loss: 0.1956 - val_acc: 0.9258\n",
      "Epoch 90/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2039 - acc: 0.9211 - val_loss: 0.1960 - val_acc: 0.9250\n",
      "Epoch 91/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2030 - acc: 0.9227 - val_loss: 0.1948 - val_acc: 0.9258\n",
      "Epoch 92/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2034 - acc: 0.9218 - val_loss: 0.1947 - val_acc: 0.9256\n",
      "Epoch 93/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2019 - acc: 0.9229 - val_loss: 0.1949 - val_acc: 0.9254\n",
      "Epoch 94/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2043 - acc: 0.9230 - val_loss: 0.1945 - val_acc: 0.9258\n",
      "Epoch 95/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2035 - acc: 0.9218 - val_loss: 0.1949 - val_acc: 0.9268\n",
      "Epoch 96/100\n",
      "31145/31145 [==============================] - 1s 40us/step - loss: 0.2030 - acc: 0.9214 - val_loss: 0.1952 - val_acc: 0.9255\n",
      "Epoch 97/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2029 - acc: 0.9216 - val_loss: 0.1958 - val_acc: 0.9254\n",
      "Epoch 98/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2032 - acc: 0.9215 - val_loss: 0.1964 - val_acc: 0.9258\n",
      "Epoch 99/100\n",
      "31145/31145 [==============================] - 1s 39us/step - loss: 0.2022 - acc: 0.9219 - val_loss: 0.1951 - val_acc: 0.9267\n",
      "Epoch 100/100\n",
      "31145/31145 [==============================] - 1s 38us/step - loss: 0.2031 - acc: 0.9215 - val_loss: 0.1945 - val_acc: 0.9259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x124329cc0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(train_new,y_train_new,batch_size=64,epochs= 100,validation_data=[valid_new,y_valid_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_transformed = np.concatenate([test_transformed,other_data_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions=model3.predict(test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"Predictions.npy\",predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
